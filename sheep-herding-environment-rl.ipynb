{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"## A simulation designed to model the movement of sheep being herded by a sheepdog\n\n### Objectives:\n- Create an environment for use in deep reinforcement learning\n- Create fast running vectorized code using numpy arrays and broadcasting\n- Model sheep using flocking behaviours (alignment, cohesion, separation)","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.animation as animation\nimport matplotlib.patches as patches\nimport heapq\n\nclass Herd:\n    def __init__(self, calculate_reward=False):\n\n        # A very small constant we use to multiply constants by for ease of reading\n        self.UNIVERSAL_MODIFIER = 1e-6\n\n        # Initialize constants\n        # Size of field\n        self.SIZE = 1\n        self.GRID_SIZE = (self.SIZE, self.SIZE)\n\n        # Dimensions of the central goal fence area\n        self.GOAL_ORIGIN = ((0.4 * self.SIZE), (0.4 * self.SIZE))\n        self.GOAL_HEIGHT = 0.2 * self.SIZE\n        self.GOAL_WIDTH = 0.2 * self.SIZE\n\n        # Max length of episode\n        self.N_STEPS = 1000\n\n        # Number of sheep to be used\n        self.N_SHEEP = 3\n\n        # Number of sheep that start inside the goal area\n        self.N_SHEEP_HERDED = 2\n\n        # Sheep max speed\n        self.MAX_SPEED_SHEEP = 7000 * self.UNIVERSAL_MODIFIER\n\n        # Dog max speed\n        self.MAX_SPEED_DOG = 12000 * self.UNIVERSAL_MODIFIER\n\n        # Maximum change of speed per time step for dog (takes 6 frames to decelerate to 0 from max speed)\n        self.MAX_ACCELERATION_DOG = 2000 * self.UNIVERSAL_MODIFIER\n\n        # Sheep speed decay, slows sheep slightly each step\n        self.SPEED_DECAY_SHEEP = 0.94\n\n        # Movement constants\n        self.MAX_RANGE_SCARE = 0.4 * self.SIZE\n        self.STRENGTH_SCARE = 25 * self.UNIVERSAL_MODIFIER\n\n        self.MAX_RANGE_EDGE = 0.03 * self.SIZE\n        self.STRENGTH_EDGE = 30 * self.UNIVERSAL_MODIFIER \n\n        self.STRENGTH_NOISE = 300 * self.UNIVERSAL_MODIFIER\n\n        self.MAX_RANGE_COHESION = 0.2 * self.SIZE\n        self.MIN_RANGE_COHESION = 0.01 * self.SIZE\n        self.STRENGTH_COHESION = 30 * self.UNIVERSAL_MODIFIER \n\n        self.MAX_RANGE_SEPARATION = 0.03 * self.SIZE\n        self.MIN_RANGE_SEPARATION = 0.001 * self.SIZE\n        self.STRENGTH_SEPARATION = 400 * self.UNIVERSAL_MODIFIER \n\n        self.MAX_RANGE_ALIGNMENT = 0.3 * self.SIZE\n        self.MIN_RANGE_ALIGNMENT = 0.01 * self.SIZE\n        self.STRENGTH_ALIGNMENT = 8000 * self.UNIVERSAL_MODIFIER \n\n        # Initialize variables\n        # Initializes an empty array for future sheep and sheepdog positions as an empty n x 2 array\n        self.dog_pos_history = np.empty((self.N_STEPS, 2))\n        self.sheep_pos_history = np.empty((self.N_STEPS, self.N_SHEEP, 2))\n\n        # Current time step of the simulation\n        self.time_step = 0 \n\n        if calculate_reward:\n            self.reward_calculator = self.RewardCalculator()\n        else:\n            self.reward_calculator = None\n\n    def reset(self):\n        '''\n        Resets the positions and velocities of the sheep and dog to random initial values.\n\n        Returns:\n            (tuple of numpy arrays): Observations from the environment.\n        '''\n        # Initializes sheep positions as random xy coordinates between 0 and size for each sheep\n        self.sheep_pos = self.spawn_sheep(self.N_SHEEP, self.N_SHEEP_HERDED)\n\n        # Initializes sheep veocities as random dx dy vectors\n        self.sheep_vel = self.MAX_SPEED_SHEEP * np.random.rand(self.N_SHEEP, 2)\n\n        # Initializes a boolean array, True if sheep is inside goal area\n        self.sheep_in_goal = np.full((len(self.sheep_pos),), False)\n\n        # Initialize dog position\n        self.dog_pos = np.array([self.SIZE/2, self.SIZE/4])\n\n        # Initialize dog velocity\n        self.dog_vel = self.MAX_SPEED_DOG * self.create_random_unit_vectors(1)\n\n        # Current step as 1, as 0 is the initial conditions\n        self.time_step = 1\n\n        return self.observe()\n\n    def step(self, action):\n        '''\n        Moves the simulation forward one step taking in an action from the dog (change in velocity).\n        Update positions and velocities of the sheep and dog. \n        Check for wall collisions and limit speeds. \n        Store positions for each step.\n        '''\n\n        action = self.limit_speed(action, self.MAX_ACCELERATION_DOG)\n        # Move the dog first\n        # Add acceleration to dog's velocity\n        self.dog_vel += action\n\n        # Immediately limit the dog's speed\n        self.dog_vel = self.limit_speed(self.dog_vel, self.MAX_SPEED_DOG)\n\n        # Move the dog\n        self.dog_pos += self.dog_vel\n        \n        # Check dog wall collision\n        self.dog_pos, self.dog_vel = self.handle_wall_collisions(self.dog_pos, self.dog_vel)\n        self.dog_pos, self.dog_vel = self.handle_fence_collisions(self.dog_pos, self.dog_vel)\n\n        # Move sheep\n        # Calculate influences on sheep, adding them to sheep velocities\n        self.apply_sheep_influences()\n\n        # Limit sheep speed\n        self.sheep_vel = self.limit_speed(self.sheep_vel, self.MAX_SPEED_SHEEP)\n\n        # Decay sheep speed\n        self.sheep_vel = self.decay_speed(self.sheep_vel, self.SPEED_DECAY_SHEEP)\n\n        # Move sheep just by current velocity\n        self.sheep_pos += self.sheep_vel\n\n        # Collisions with outer walls\n        self.sheep_pos, self.sheep_vel = self.handle_wall_collisions(self.sheep_pos, self.sheep_vel)\n\n        # Check if any sheep are inside the goal\n        self.check_sheep_inside_goal()\n\n        # Write to storage variables\n        self.dog_pos_history[self.time_step] = self.dog_pos\n        self.sheep_pos_history[self.time_step] = self.sheep_pos\n        self.time_step += 1\n\n        return self.calculate_reward(), self.observe(), self.is_done(), self.get_info()\n\n    def apply_sheep_influences(self):\n        '''\n        Determine the influence on sheep based on:\n            Random noise (random noise is added each time step to simulate randomness)\n            Fear of the dog (sheep are strongly repelled by the dog)\n            Fear of the edges (sheep are repelled away from nearby edges)\n            Flocking - Coherence (sheep are attracted to sheep in a medium distance)\n            Flocking - Separation (sheep are repelled by sheep in a short distance)\n            Flocking - Alignment (sheep move in the same direction as nearby sheep)\n\n        The method calculates influences, sums them up and adds them to each sheep's current velocity.\n        '''\n        def calculate_noise_influence():\n            '''\n            Calculate the noise influence on the sheep.\n\n            The method generates a random unit vector for each sheep to represent the random component \n            of the sheep's movement, also known as the \"noise\" influence.\n\n            Returns:\n                np.array: A 2D array representing the noise influence on each sheep.\n                Each row corresponds to a single sheep, while the two columns denote the x and y components of the influence, respectively.\n            '''\n            # Multiply strength of noise coefficient by random unit vectors (Gaussian noise)\n            return self.STRENGTH_NOISE * self.create_random_unit_vectors(self.N_SHEEP)\n\n        def calculate_scare_influence():\n            '''\n            Calculate the scare influence on the sheep.\n\n            The method calculates the distance and direction between each sheep and the dog, and \n            determines the influence the dog has on each sheep based on these values. The closer \n            the dog is to a sheep, the greater the influence.\n\n            Returns:\n                np.array: A 2D array representing the scare influence on each sheep.\n                Each row corresponds to a single sheep, while the two columns denote the x and y components of the influence, respectively.\n            '''\n            # Calculate vectors pointing from dog to sheep for each sheep\n            unit_vectors, magnitudes = self.cartesian_to_norm_magnitude(self.sheep_pos - self.dog_pos)\n\n            # This vector multiplied by a scale factor for every sheep within range\n            influences = np.where(magnitudes < self.MAX_RANGE_SCARE, self.STRENGTH_SCARE * unit_vectors / (magnitudes ** 2), np.array([0, 0]))\n\n            # Sheep within the central fence have no fear\n            return influences * (np.logical_not(self.sheep_in_goal)[:, np.newaxis])\n        \n        def calculate_edge_influence():\n            '''\n            Calculates the influence of proximity to the edge on each sheep.\n\n            This method first determines the distance from each sheep to each of the four edges of the simulation area.\n            Then, it computes the corresponding influence for both x and y directions.\n            This influence is then adjusted for direction (positive for left and bottom edges, negative for right and top edges)\n            and the total edge influence is calculated by summing influences from both directions.\n\n            Returns:\n                np.array: A 2D array representing the edge influence on each sheep.\n                Each row corresponds to a single sheep, while the two columns denote the x and y components of the influence, respectively.\n            '''\n\n            # Calculate the distance from the sheep to each of the four edges\n            # Numpy arrays are of this shape [[[left, right][bottom, top]],[[left,right]...]]\n            distances = np.stack([self.sheep_pos, self.SIZE - self.sheep_pos], axis=-1)\n\n            # Compute influence in both x and y directions\n            influences = np.where(distances < self.MAX_RANGE_EDGE, self.STRENGTH_EDGE / distances, 0)\n                    \n            # Correct the sign of the influence (negative for right and top edges)\n            influences[..., 1] *= -1\n\n            return np.sum(influences, axis=-1)\n\n        def calculate_cohesion_influence():\n            '''\n            Calculates the influence of cohesion (attraction to the flock) on each sheep.\n\n            The method first computes the distance and direction from each sheep to every other sheep.\n            Then, it calculates the influence of other sheep that are within a certain range.\n            The final influence is the mean of these individual influences.\n\n            Returns:\n                np.array: A 2D array representing the cohesion influence on each sheep.\n                Each row corresponds to a single sheep, while the two columns denote the x and y components of the influence, respectively.\n            '''\n            # We expand the sheep pos array so we get a new array of shape [[[x1,y1]],[[x2, y2]],[[x3, y3]]]\n            # When we subtract with this array, we will use this shape to make a new array of shape\n            # [[[x1-x1, y1-y1],[x2-x1, y2-y1], [x3-x1, y3-y1]],\n            #  [[x1-x2, y1-y2],[x2-x2, y2-y2], [x3-x2, y3-y2]],\n            #  [[x1-x3, y1-y3],[x2-x3, y2-y3], [x3-x3, y3-y3]]]\n            # We then get the unit vectors and magnitudes for each of these by using numpy broadcasting on these vector arrays\n            unit_vectors, magnitudes = self.cartesian_to_norm_magnitude(self.sheep_pos - np.expand_dims(self.sheep_pos, axis=1))\n\n            # Create vectorized condition\n            condition = np.logical_and((magnitudes <= self.MAX_RANGE_COHESION), (magnitudes >= self.MIN_RANGE_COHESION))\n\n            # Calculate influences if they are within range\n            influences = np.where(condition, self.STRENGTH_COHESION * unit_vectors / magnitudes, np.array([0, 0]))\n\n            # Return the mean over the second axis\n            return influences.mean(axis=1)\n        \n        def calculate_separation_influence():\n            '''\n            Calculates the influence of separation (repulsion from nearby sheep) on each sheep.\n\n            The method first computes the distance and direction from each sheep to every other sheep.\n            Then, it calculates the negative influence of other sheep that are within a certain range,\n            representing a repulsion effect. The final influence is the mean of these individual influences.\n\n            Returns:\n                np.array: A 2D array representing the separation influence on each sheep.\n                Each row corresponds to a single sheep, while the two columns denote the x and y components of the influence, respectively.\n            '''\n            # The same method is used to calculate cohesion influence\n            unit_vectors, magnitudes = self.cartesian_to_norm_magnitude(self.sheep_pos - np.expand_dims(self.sheep_pos, axis=1))\n            condition = np.logical_and((magnitudes <= self.MAX_RANGE_SEPARATION), (magnitudes >= self.MIN_RANGE_SEPARATION))\n\n            # The only difference is that separation is negative\n            influences = -np.where(condition, self.STRENGTH_SEPARATION * unit_vectors / magnitudes, np.array([0, 0]))\n            return influences.mean(axis=1)\n        \n        def calculate_alignment_influence():\n            '''\n            Calculates the influence of alignment (movement in the same direction as nearby sheep) on each sheep.\n\n            This method first computes the distance from each sheep to every other sheep.\n            Then, it calculates the influence of other sheep that are within a certain range, multiplied by the velocity of each sheep,\n            representing an alignment effect. The final influence is the mean of these individual influences.\n\n            Returns:\n                alignment_influence (np.array): A 2D array representing the alignment influence on each sheep.\n                Each row corresponds to a single sheep, while the two columns denote the x and y components of the influence, respectively.\n            '''\n            # The same method is used to begin calculating alignment\n            _, magnitudes = self.cartesian_to_norm_magnitude(self.sheep_pos - np.expand_dims(self.sheep_pos, axis=1))\n            condition = np.logical_and((magnitudes <= self.MAX_RANGE_ALIGNMENT), (magnitudes >= self.MIN_RANGE_ALIGNMENT))\n            \n            # Only instead we discard the unit vectors and multiply by the velocities of each sheep\n            influences = np.where(condition, self.STRENGTH_ALIGNMENT * self.sheep_vel / magnitudes, np.array([0, 0]))\n            return influences.mean(axis=1)\n        \n        def calculate_fence_influence():\n            '''\n            Calculates the influence of the fence on each sheep.\n\n            The method first computes the distance from each sheep to the fence in the left, right, and top.\n            Then, it calculates the influence of the fence that are within a certain range.\n            The final influence is the sum of these individual influences.\n\n            Returns:\n                np.array: A 2D array representing the fence influence on each sheep.\n                Each row corresponds to a single sheep, while the two columns denote the x and y components of the influence, respectively.\n            '''\n\n            # Fence boundaries\n            fence_left = self.GOAL_ORIGIN[0]\n            fence_right = self.GOAL_ORIGIN[0] + self.GOAL_WIDTH\n            fence_top = self.GOAL_ORIGIN[1] + self.GOAL_HEIGHT\n            fence_bottom = self.GOAL_ORIGIN[1]\n\n            # Calculate distances to each fence boundary\n            dist_to_left = self.sheep_pos[:,0] - fence_left\n            dist_to_right = fence_right - self.sheep_pos[:,0]\n            dist_to_top = fence_top - self.sheep_pos[:,1]\n            dist_to_bottom = self.sheep_pos[:,1] - fence_bottom\n\n\n            # Find out which sheep are within the effective range of the fence.\n            close_to_left = np.logical_and(dist_to_left <= self.MAX_RANGE_EDGE, np.logical_and(self.sheep_pos[:,1] >= self.GOAL_ORIGIN[1], self.sheep_pos[:,1] <= fence_top))\n            close_to_right = np.logical_and(dist_to_right <= self.MAX_RANGE_EDGE, np.logical_and(self.sheep_pos[:,1] >= self.GOAL_ORIGIN[1], self.sheep_pos[:,1] <= fence_top))\n            close_to_top = np.logical_and(dist_to_top <= self.MAX_RANGE_EDGE, np.logical_and(self.sheep_pos[:,0] >= fence_left, self.sheep_pos[:,0] <= fence_right))\n            close_to_bottom = np.logical_and(self.sheep_in_goal, np.logical_and(dist_to_bottom <= self.MAX_RANGE_EDGE, np.logical_and(self.sheep_pos[:,0] >= fence_left, self.sheep_pos[:,0] <= fence_right)))\n\n\n            # Calculate the influences\n            left_influences = np.where(close_to_left, self.STRENGTH_EDGE / dist_to_left, 0)[:, np.newaxis]\n            right_influences = -np.where(close_to_right, self.STRENGTH_EDGE / dist_to_right, 0)[:, np.newaxis]\n            top_influences = -np.where(close_to_top, self.STRENGTH_EDGE / dist_to_top, 0)[:, np.newaxis]\n            bottom_influences = np.where(close_to_bottom, self.STRENGTH_EDGE / dist_to_bottom, 0)[:, np.newaxis]\n\n            # Combine influences.\n            x_influences = left_influences + right_influences\n            y_influences = top_influences + bottom_influences\n\n            influences = np.hstack([x_influences, y_influences])\n\n            return influences\n\n\n        self.sheep_vel += calculate_noise_influence() + calculate_edge_influence() + calculate_scare_influence() + \\\n         calculate_cohesion_influence() + calculate_separation_influence() + calculate_alignment_influence() + calculate_fence_influence()\n\n    def handle_wall_collisions(self, positions, velocities):\n        '''\n        Check if sheep or dog have hit a boundary (wall). If so, reflect their positions and velocities accordingly.\n        \n        Args:\n            positions (np.array): Positions of the sheep or the dog.\n            velocities (np.array): Velocities of the sheep or the dog.\n\n        Returns:\n            positions (np.array): Updated positions.\n            velocities (np.array): Updated velocities.\n        '''\n        \n        # Find positions that exceed the area boundaries\n        reflect = np.where((positions < 0) | (positions > self.SIZE), -1, 1)\n        \n        # Reflect velocities and positions\n        positions, velocities = positions * reflect, velocities * reflect\n\n        # Positions were over the upper/lower boundaries need double the size added back\n        positions = np.where(positions < -self.SIZE, 2*self.SIZE + positions, positions)\n   \n        return positions, velocities\n    \n    def handle_fence_collisions(self, positions, velocities):\n        '''\n        Prevent the dog from entering the fenced area.\n        If the dog is within the fence boundaries, it calculates the closest boundary,\n        reverses the corresponding velocity component, and adds that velocity to the dog's\n        current position to ensure it leaves the boundary.\n        \n        Args:\n            positions (np.array): Positions of the dog.\n            velocities (np.array): Velocities of the dog.\n\n        Returns:\n            positions (np.array): Updated positions.\n            velocities (np.array): Updated velocities.\n        '''\n        \n        # Fence boundaries\n        fence_left = self.GOAL_ORIGIN[0]\n        fence_right = self.GOAL_ORIGIN[0] + self.GOAL_WIDTH\n        fence_top = self.GOAL_ORIGIN[1] + self.GOAL_HEIGHT\n        fence_bottom = self.GOAL_ORIGIN[1]\n        \n        # Check if dog is within the fence boundaries\n        within_fence = np.logical_and(\n            np.logical_and(fence_left <= positions[0], positions[0] <= fence_right),\n            np.logical_and(fence_bottom <= positions[1], positions[1] <= fence_top)\n        )\n        \n        if within_fence:\n            # Calculate distances to each fence boundary\n            dist_to_left = abs(positions[0] - fence_left)\n            dist_to_right = abs(fence_right - positions[0])\n            dist_to_top = abs(fence_top - positions[1])\n            dist_to_bottom = abs(positions[1] - fence_bottom)\n            \n            # Find the minimum distance\n            min_dist = min(dist_to_left, dist_to_right, dist_to_top, dist_to_bottom)\n            \n            if (min_dist == dist_to_left) or (min_dist == dist_to_right):\n                velocities[0] = -velocities[0]*0.75  # Mirror x velocity\n            elif (min_dist == dist_to_top) or (min_dist == dist_to_bottom):\n                velocities[1] = -velocities[1]*0.75  # Ensure velocity points down\n\n            # Add velocity to current position to move dog out of the boundary\n            positions += velocities\n\n        return positions, velocities\n    \n\n    def check_sheep_inside_goal(self):\n        # Smaller goal boundaries\n        smaller_goal_origin = (self.GOAL_ORIGIN[0] * 1.005, self.GOAL_ORIGIN[1] * 1.005)\n        smaller_goal_width = self.GOAL_WIDTH * 0.99\n        smaller_goal_height = self.GOAL_HEIGHT * 0.99\n        \n        fence_left = smaller_goal_origin[0]\n        fence_right = smaller_goal_origin[0] + smaller_goal_width\n        fence_top = smaller_goal_origin[1] + smaller_goal_height\n        fence_bottom = smaller_goal_origin[1]\n\n        self.sheep_in_goal = np.logical_and(np.logical_and(self.sheep_pos[:,0] >= fence_left, self.sheep_pos[:,0] <= fence_right),\n                                            np.logical_and(self.sheep_pos[:,1] >= fence_bottom, self.sheep_pos[:,1] <= fence_top))\n    \n    def create_random_unit_vectors(self, n:int):\n        '''\n        Helper function, creates n many randomly oriented unit vectors.\n\n        Args:\n            n (int): The number of unit vectors to generate.\n        \n        Returns:\n            (n x 2 numpy array): An array of randomly oriented unit vectors\n        '''\n        random_vectors = np.random.normal(size=(n, 2))\n        unit_vectors, _ = self.cartesian_to_norm_magnitude(random_vectors)\n        return np.squeeze(unit_vectors)\n    \n    def spawn_outside_goal(self):\n        '''\n        Returns coordinates that are outside of the goal area.\n        '''\n        pos = np.random.rand(1, 2) * np.array([0.6, 0.4])\n\n        def f1(x): return x\n        def f2(x): return np.flip(x) + np.array([0.6, 0])\n        def f3(x): return x + np.array([0.4, 0.6])\n        def f4(x): return np.flip(x) + np.array([0, 0.4])\n\n        return self.SIZE * np.random.choice([f1, f2, f3, f4])(pos)\n\n    def spawn_inside_goal(self):\n        '''\n        Returns coordinates inside the goal area.\n        '''\n        return self.SIZE * (np.random.rand(1, 2) * 0.2) + np.array([0.4, 0.4])\n        \n    def spawn_sheep(self, n_sheep, n_inside=0):\n        sheep_pos = np.zeros([n_sheep, 2])\n        for i in range(n_sheep):\n            if i < n_inside:\n                sheep_pos[i] = self.spawn_inside_goal()\n            else:\n                sheep_pos[i] = self.spawn_outside_goal()\n\n        # Changing the order is important so sheep in goal aren't always in the same array indices\n        np.random.shuffle(sheep_pos)\n        return sheep_pos\n\n    @staticmethod\n    def cartesian_to_norm_magnitude(cartesian_coords):\n        '''\n        Converts Cartesian coordinates to normalized coordinates and calculates the magnitude.\n\n        Args:\n            cartesian_coords (np.array): Array containing Cartesian coordinates.\n\n        Returns:\n            normalized (np.array): Array containing normalized coordinates.\n            magnitudes (np.array): Array containing magnitudes of each vector passed in.\n\n        '''\n        # We the axis=-1 means we get the magnitudes of the innermost objects (vectors)\n        # We add a very small value to the magnitudes to avoid divide-by-zero issues.\n        magnitudes = np.linalg.norm(cartesian_coords, axis=-1, keepdims=True) + 1e-8\n\n        return cartesian_coords / magnitudes, magnitudes\n\n    @staticmethod\n    def limit_speed(velocities, max_speed):\n        '''\n        Limit the speed (magnitude of velocity vectors) to a maximum value.\n\n        Args:\n            velocities (np.array): Array containing velocity vectors.\n            max_speed (float): Maximum allowable speed.\n\n        Returns:\n            np.array: Array containing the velocity vectors, limited to the maximum speed.\n        '''\n        # Prevents divide by 0 errors for dog\n        if (velocities == np.array([0,0])).all():\n            return velocities\n        \n        # Compute the magnitude of each vector\n        magnitudes = np.linalg.norm(velocities, axis=-1, keepdims=True)\n        \n        return velocities * np.minimum(max_speed / magnitudes, 1)\n    \n    @staticmethod\n    def decay_speed(velocities, decay_rate):\n        '''\n        Reduces the magnitude of by multiplying by a decay rate.\n        \n        Args:\n            velocities (np.array): Array containing velocity vectors.\n            decay_rate (float): Rate at which to decay the speed per time step.\n\n        Returns:\n            reduced_velocities (np.array): Array containing the velocity vectors, reduced by decay rate.\n        '''\n        return decay_rate * velocities\n    \n\n    def initialize_scatter(self):\n        '''\n        Initializes the scatter plot for visualization of the movement of the sheep and sheepdog.\n        \n        Returns:\n            scatter_sheep (matplotlib.collections.PathCollection): Scatter plot object for the sheep.\n            scatter_dog (matplotlib.collections.PathCollection): Scatter plot object for the dog.\n        '''\n        color_grass = '#B6E880'\n        color_fence = '#555555'\n\n        # Initialize figure and axis\n        self.fig, self.ax = plt.subplots(figsize=(7, 7))\n        self.ax.set_facecolor(color_grass)\n        self.ax.set_xlim([0, self.SIZE])\n        self.ax.set_ylim([0, self.SIZE])\n\n        # Scatter plot to represent sheep and sheepdog\n        self.scatter_sheep = self.ax.scatter(self.sheep_pos_history[0,:,0],self.sheep_pos_history[0,:,1]  , c='white', edgecolor=\"gray\", linewidth=0.8, alpha=0.8)\n        self.scatter_dog = self.ax.scatter(self.dog_pos_history[0, 0], self.dog_pos_history[0,1], s=35, c='white', edgecolor=\"black\", linewidth=0.8)\n\n        fence_rectangle = patches.Rectangle(self.GOAL_ORIGIN, self.GOAL_WIDTH, self.GOAL_HEIGHT, fc='#B6E880', edgecolor=color_fence, linewidth=2.5)\n\n        # Overwrite bottom edge of fence to make it invisible\n        bottom_edge = patches.Polygon([(self.GOAL_ORIGIN[0]*1.01, self.GOAL_ORIGIN[1]), ((self.GOAL_ORIGIN[0]+self.GOAL_WIDTH)*0.995, self.GOAL_ORIGIN[1])], closed=False, fill=True, edgecolor=color_grass, facecolor='white', linewidth=3)\n\n        # Add patch and fence to plot\n        self.ax.add_patch(fence_rectangle)\n        self.ax.add_patch(bottom_edge)\n\n        return self.scatter_sheep, self.scatter_dog\n    \n    def update_scatter(self, i): \n        '''\n        Updates the scatter plot for each frame of the animation.\n        \n        Args:\n            i (int): Current frame number in the animation.\n\n        Returns:\n            scatter_sheep (matplotlib.collections.PathCollection): Updated scatter plot object for the sheep.\n            scatter_dog (matplotlib.collections.PathCollection): Updated scatter plot object for the dog.\n        '''\n        self.scatter_sheep.set_offsets(self.sheep_pos_history[i])\n        self.scatter_dog.set_offsets(self.dog_pos_history[i])\n        return self.scatter_sheep, self.scatter_dog\n\n    def plot_scatter(self):\n        '''\n        Plots an animated scatter plot, showing the movement of the sheep and sheepdog over time.\n        '''\n        FRAMERATE = 30\n\n        ani = animation.FuncAnimation(self.fig, self.update_scatter, interval=round(1000/FRAMERATE), frames=self.N_STEPS, blit=True)\n        plt.close()\n\n    def observe(self):\n        '''\n        Gets current observations from the environment.\n        Returns the following information contained in a tuple.\n\n        Returns:\n            self.dog_pos (np.array): Numpy array of shape [x, y]\n            self.dog_vel (np.array): Numpy array of shape [x, y]\n            self.sheep_pos (np.array): Numpy array of shape [[x1, y1], [x2, y2]...]\n            self.sheep_vel (np.array): Numpy array of shape [[x1, y1], [x2, y2]...]\n        '''\n        return (self.dog_pos, self.dog_vel, self.sheep_pos, self.sheep_vel)\n    \n    def calculate_reward(self):\n        '''\n        Calculates the reward in the current state of the environment.\n        If we have a reward calculator object attached, it will return the reward calculated from that.\n        Otherwise, we just return 0 as a dummy value.\n        '''\n        if self.reward_calculator:\n            return self.reward_calculator.calc_reward(self.observe())\n        else:\n            return 0\n\n    def is_done(self):\n        '''\n        Flag that checks if the environment has finished running.\n\n        Returns:\n            bool: True if the environment has finished running, False otherwise.\n        '''\n        done = self.time_step >= self.N_STEPS or sum(self.sheep_in_goal) == self.N_SHEEP\n\n        return done\n    \n    def get_info(self):\n        '''\n        Method to fetch additional information about the current state of the environment.\n        \n        Returns:\n            tuple: Currently returns an empty tuple. \n                (Will be implemented in future to return additional environment information.)\n        '''\n        return ()\n    \n    class RewardCalculator():\n        def __init__(self):\n            # Constants\n            self.SIZE = 1000 # Precision of reward prediction (higher takes longer time to compute intial Dijkstra's)\n            self.goal_reward = 10\n            self.previous_reward = None  # For use with potential rewards\n\n            # Initialize the grid\n            grid = np.ones((self.SIZE, self.SIZE))\n\n            # Define the boundaries\n            left, right = int(self.SIZE*0.4), int(self.SIZE*0.6)\n            bottom, top = int(self.SIZE*0.4), int(self.SIZE*0.6)\n\n            # Set the fence boundaries as obstacles, value = np.inf\n            grid[bottom:top+1, left] = np.inf  # Left fence\n            grid[bottom:top+1, right] = np.inf  # Right fence\n            grid[top, left:right+1] = np.inf  # Top fence\n\n            # Points on the entrance line\n            starts = [(bottom, x) for x in range((left+(1*self.SIZE//25)), (right-(1*self.SIZE//25)+1), 1)]  \n\n            # Perform the Dijkstra algorithm for two sets of start points\n            chosen_point = (self.SIZE//35, self.SIZE//2)\n            distances1 = self.dijkstra(grid, starts)\n            distances2 = self.dijkstra(grid, [chosen_point])\n\n            # Add the two distance grids together\n            combined_distances = distances1 + 0.3 * distances2\n\n            # Normalize the combined distances to range [0, 1]\n            max_combined_distance = np.max(combined_distances[np.isfinite(combined_distances)])\n            combined_distances = combined_distances / max_combined_distance\n\n            # Fix fence values\n            combined_distances[bottom:top+1, left] = combined_distances[bottom:top+1, left-1]\n            combined_distances[bottom:top+1, right] = combined_distances[bottom:top+1, right+1]\n            combined_distances[top, left:right+1] = combined_distances[top + 1, left:right+1]\n\n            # Set the distances inside the square to be very low\n            combined_distances[bottom:top, left+1:right] = 0\n\n            self.reward_grid = combined_distances\n\n        def dijkstra(self, grid, starts):\n            height, width = grid.shape\n            dist = np.full((height, width), np.inf)\n            for start in starts:\n                dist[start] = 0\n            pq = [(0, start) for start in starts]\n\n            while pq:\n                d, (x, y) = heapq.heappop(pq)\n                if d != dist[x, y]: continue\n                for dx, dy in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n                    nx, ny = x + dx, y + dy\n                    if (0 <= nx < height and 0 <= ny < width and dist[nx, ny] > dist[x, y] + grid[nx, ny]):\n                        if np.isinf(grid[nx, ny]): continue  # If cell is an obstacle (part of the fence)\n                        dist[nx, ny] = dist[x, y] + grid[nx, ny]\n                        heapq.heappush(pq, (dist[nx, ny], (nx, ny)))\n\n            return dist\n\n        def calc_reward(self, obs):\n            # This is not an optimized function as we're iterating over each element\n            reward_list = []\n\n            # For each sheep\n            for pos in obs[2]:\n                # Does it fit inside the goal area\n                if (pos[0] > 0.4) and (pos[0] < 0.6) and (pos[1] > 0.4) and (pos[1] < 0.6):\n                    reward_list.append(self.goal_reward)\n                    continue\n                \n                # Else find its grid location and add the corresponding reward to the reward list\n                new_pos = np.floor(pos * self.SIZE).astype(int)\n                reward = self.reward_grid[new_pos[0], new_pos[1]]\n                reward_list.append(reward)\n                \n            current_reward = np.mean(reward_list)\n\n            # If this is not our first reward, return the potential reward\n            if self.previous_reward:\n                potential_reward = current_reward - self.previous_reward\n                self.previous_reward = current_reward\n                return potential_reward\n\n            # If this is our first reward, set it as our previous reward, then save our current reward\n            else:\n                self.previous_reward = current_reward\n                return 0.\n\n\n\nclass SimpleAgent:\n    def __init__(self, continuous=True):\n        self.total_reward = 0\n        self.rewards = []\n\n    def discrete_action_wrapper(self, action):\n        if action == 0:\n            return np.array([0, 0])\n        elif action == 1:\n            return np.array([-1, 0])\n        elif action == 2:\n            return np.array([-0.70710678, 0.70710678])\n        elif action == 3:\n            return np.array([0, 1])\n        elif action == 4:\n            return np.array([0.70710678, 0.70710678])\n        elif action == 5:\n            return np.array([1, 0])\n        elif action == 6:\n            return np.array([0.70710678, -0.70710678])\n        elif action == 7:\n            return np.array([0, -1])\n        elif action == 8:\n            return np.array([-0.70710678, -0.70710678])\n\n    def reset(self):\n        '''\n        Resets total reward for agent.\n        '''\n        self.total_reward = 0\n\n    def select_action(self, env):\n        '''\n        Selects an action based off of the current policy.\n        The policy for this simple agent is to move in the opposite direction when near the edge of the environment.\n        '''\n        acceleration = np.array([0, 0])\n\n        dog_pos, _, _, _ = env.observe()\n\n        # 1/boundary is the percentage of the screen size dog will start accelerating away from as it reaches it\n        boundary = 20\n        if dog_pos[0] > (boundary-1)*env.SIZE/boundary:\n            acceleration[0] = -1\n        if dog_pos[1] > (boundary-1)*env.SIZE/boundary:\n            acceleration[1] = -1\n        if dog_pos[0] < env.SIZE/boundary:\n            acceleration[0] = 1\n        if dog_pos[1] < env.SIZE/boundary:\n            acceleration[1] = 1\n\n        return acceleration\n\n    def step(self, env: Herd):\n        '''\n        Takes a step in the environment.\n        '''\n        action = self.select_action(env)\n        reward, next_obs, done, info = env.step(action)\n        self.total_reward += reward\n        self.rewards.append(reward)\n \n\ndef play_episode(env: Herd, agent):\n    '''\n    Runs one complete episode in a Herd environment.\n\n    Args:\n        env (Herd): The environment in which the agent operates.\n        agent (SimpleAgent): The agent that is interacting with the environment.\n    '''\n    env.reset()\n    while env.is_done() == False:\n        agent.step(env)\n    env.initialize_scatter()\n    env.plot_scatter()\n\nagent = SimpleAgent()\nenv = Herd(calculate_reward=False)\n\nplay_episode(env, agent)","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2023-09-09T09:03:41.620100Z","iopub.execute_input":"2023-09-09T09:03:41.620474Z","iopub.status.idle":"2023-09-09T09:03:42.333268Z","shell.execute_reply.started":"2023-09-09T09:03:41.620446Z","shell.execute_reply":"2023-09-09T09:03:42.331572Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":"![](https://s11.gifyu.com/images/S4b3G.gif)","metadata":{}}]}